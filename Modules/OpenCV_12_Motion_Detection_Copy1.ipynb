{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "OpenCV 12 Motion Detection- Copy1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJClFELA1Uus"
      },
      "source": [
        "# OpenCV Motion Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6KYKAAB1Uu4"
      },
      "source": [
        "This program uses the difference between two consecutive frames of video and finds contours, based on the difference image. The area of contours is checked (if it is above a threshold value then only it is considered). Based on the coordinates of the contours, it is enclosed in a rectangle.\n",
        "\n",
        "1. You have to provide location of the video which you want to process. If you want to use your Web Cam then enter 0 in the File location.\n",
        "2. Provide the location of Folder or Desktop where you want to save the processed video (For Ex: C:/Users/Desktop/MOTION DETECTION.avi)\n",
        "3. Click 'Esc' to terminate the window.\n",
        "\n",
        "NOTE: This code is completely based on CV library and does not use any ML models.\n",
        "      Provide locations of files correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR_TIr7M1Uu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c694ebb-51fa-49e1-c289-0ac16e9c3fba"
      },
      "source": [
        "import cv2\n",
        "import datetime\n",
        "\n",
        "# file = \"E:/DataSet/AutomatedSurveil/MotionDetection/CarRace.mp4\"\n",
        "# result=\"E:/DataSet/AutomatedSurveil/Results\"\n",
        "\n",
        "def Processing(file, file_save):\n",
        "    if file == '0':\n",
        "        file = int(file)\n",
        "        \n",
        "    cap = cv2.VideoCapture(file)\n",
        "\n",
        "    ret,frame1 = cap.read()\n",
        "    ret,frame2 = cap.read()\n",
        "    \n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    Output = cv2.VideoWriter(file_save, fourcc, 20.0, (640, 352))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        diff = cv2.absdiff(frame1,frame2)\n",
        "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
        "        blur = cv2.GaussianBlur(gray,(9,9),0)\n",
        "        _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
        "        dilated = cv2.dilate(thresh, None, iterations = 3)\n",
        "        contours, hierarchy = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        datex = str(datetime.datetime.now())\n",
        "        font = cv2.FONT_HERSHEY_TRIPLEX\n",
        "        cv2.putText(frame1,datex,(10,20),font,0.5,(255,255,255),1,cv2.LINE_AA)\n",
        "\n",
        "\n",
        "        if contours == None :\n",
        "\n",
        "            cv2.putText(frame1, \"STATUS : STATIONARY\", (480,15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 2)\n",
        "\n",
        "        else :\n",
        "            for contour in contours :\n",
        "                (x, y, w, h) = cv2.boundingRect(contour)\n",
        "                if cv2.contourArea(contour) < 1000 :\n",
        "    #                 cv2.putText(frame1, \"STATUS : STATIONARY\", (480,15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 2)\n",
        "                    continue\n",
        "                cv2.rectangle(frame1, (x,y), (x+w,y+h), (0,255,0), 2)\n",
        "                cv2.putText(frame1, \"STATUS : MOVEMENT\", (480,15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 2)\n",
        "#                 cv2.drawContours(frame1, contours, -1, (255,255,0), 2)\n",
        "        cv2.imshow('FEED', frame1)\n",
        "        B = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "        L = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "\n",
        "        Output.write(frame1)\n",
        "        frame1 = frame2\n",
        "        ret, frame2 = cap.read()\n",
        "\n",
        "        if cv2.waitKey(40) == 27 :\n",
        "            break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "File = \"E:/DataSet/AutomatedSurveil/MotionDetection/TownCenter.mp4\" #input('\\nEnter location of video: ')\n",
        "File_Save = \"E:/DataSet/AutomatedSurveil/Results/TownCenterResult.avi\" #input('\\nEnter the location to save video: ')\n",
        "\n",
        "Processing(File, File_Save)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Enter location of video: E:\\\\DataSet\\\\AutomatedSurveil\\\\MotionDetection\\\\TownCenter.mp4\n",
            "\n",
            "Enter the location to save video: E:/DataSet/AutomatedSurveil/Results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eNYEtVz1Uu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10329950-c933-4a00-cc3d-f97b318ece87"
      },
      "source": [
        "File"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'E:\\\\\\\\DataSet\\\\\\\\AutomatedSurveil\\\\\\\\MotionDetection\\\\\\\\TownCenter.mp4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}