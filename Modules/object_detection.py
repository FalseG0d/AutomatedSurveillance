# -*- coding: utf-8 -*-
"""Object Detection using Tensornets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dD9SicNxkj95WgI5l8zjM1-fsxhuYc4O
"""

!pip install git+https://github.com/taehoonlee/tensornets.git

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
import tensornets as nets
import cv2
import numpy as np
import time

inputs = tf.placeholder(tf.float32, [None, 416, 416, 3])
model = nets.YOLOv3COCO(inputs, nets.Darknet19)
# model = nets.YOLOv2(inputs, nets.Darknet19)
#frame=cv2.imread("D://pyworks//yolo//truck.jpg",1)
from google.colab import drive
drive.mount('/content/drive')

import matplotlib.pyplot as plt
classes={'0':'person'} # '1':'bicycle','2':'car','3':'bike','5':'bus','7':'truck'
list_of_classes=[0,1,2,3,5,7]
s=0
with tf.Session() as sess:
    sess.run(model.pretrained())
#"D://pyworks//yolo//videoplayback.mp4"    

    # uploaded = files.upload()
    cap = cv2.VideoCapture('/content/drive/My Drive/Cam Detection.mp4')
    fourcc = cv2.VideoWriter_fourcc(*'XVID') #codec
    Output = cv2.VideoWriter('/content/drive/My Drive/Processed Video.avi', fourcc, 20.0, (416,416), True)
    print('Drive Opened')
    
    while(cap.isOpened()):
        ret, frame = cap.read()
        # print(frame.shape)
        img=cv2.resize(frame,(416,416))
        imge=np.array(img).reshape(-1,416,416,3)
        start_time=time.time()
        preds = sess.run(model.preds, {inputs: model.preprocess(imge)})
    
        print("--- %s seconds ---" % (time.time() - start_time)) 
        boxes = model.get_boxes(preds, imge.shape[1:3])
        # cv2.namedWindow('image',cv2.WINDOW_NORMAL)

        # cv2.resizeWindow('image', 700,700)
        #print("--- %s seconds ---" % (time.time() - start_time)) 
        boxes1=np.array(boxes)
        for j in list_of_classes:
            count =0
            if str(j) in classes:
                lab=classes[str(j)]
            if len(boxes1) !=0:
                
                
                for i in range(len(boxes1[j])):
                    box=boxes1[j][i] 
                    
                    if boxes1[j][i][4]>=.40:
                                                
                        count += 1    
 
                        cv2.rectangle(img,(box[0],box[1]),(box[2],box[3]),(0,255,0),1)
#                        cv2.putText(img, lab, (box[0],box[1]), cv2.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255), lineType=cv2.LINE_AA)
            print(lab,": ",count)
    
              
        # cv2.imshow("image",img)  
        Output.write(img)
        print('Frame: ',s)
        s = s+1

        # load image using cv2....and do processing.
#        img=cv2.resize(img,(640,360))

        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        # as opencv loads in BGR format by default, we want to show it in RGB.
        plt.show()

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break          

cap.release()
cv2.destroyAllWindows()    

print('Execution Successful')

